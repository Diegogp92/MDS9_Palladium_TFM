{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d1d2eb",
   "metadata": {},
   "source": [
    "#### Preparativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327819ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\programdata\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\diego\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\diego\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "# Instalaciones\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc8cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c2cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deslimitar/Limitar display Pandas\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90f82f",
   "metadata": {},
   "source": [
    "#### Preparación Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcab5713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\AppData\\Local\\Temp\\ipykernel_16496\\2151874057.py:3: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df0 = pd.read_csv(r'D:\\DEV\\Python\\00_TFM_PALLADIUM\\02_DATASETS_GENERADOS\\Reservas_Feature_Engineered_v1.csv', sep = ';', decimal=',')\n"
     ]
    }
   ],
   "source": [
    "# Read Matches data\n",
    "\n",
    "df0 = pd.read_csv(r'D:\\DEV\\Python\\00_TFM_PALLADIUM\\02_DATASETS_GENERADOS\\Reservas_Feature_Engineered_v1.csv', sep = ';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d3660",
   "metadata": {},
   "source": [
    "#### Preparación de un DF Mixto para CatBoost Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daa2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db0bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconfigurar dtypes\n",
    "\n",
    "df_mix.drop(columns=['ID_RESERVA'], inplace=True) # No usar, ID\n",
    "df_mix.drop(columns=['ID_HOTEL'], inplace=True) # No usar, ID\n",
    "df_mix['HOTEL'] = df_mix['HOTEL'].astype('category', errors='raise')\n",
    "df_mix.drop(columns=['LLEGADA'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix.drop(columns=['LLEGADA_ANO'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix['LLEGADA_MES'] = pd.to_numeric(df_mix['LLEGADA_MES'], errors='raise').astype('category')\n",
    "df_mix['LLEGADA_DIAm'] = pd.to_numeric(df_mix['LLEGADA_DIAm'], errors='raise').astype('category')\n",
    "df_mix['LLEGADA_DIAs'] = pd.to_numeric(df_mix['LLEGADA_DIAs'], errors='raise').astype('category')\n",
    "df_mix['LLEGADA_AVANCE'] = pd.to_numeric(df_mix['LLEGADA_AVANCE'], errors='raise').astype(float)\n",
    "df_mix.drop(columns=['SALIDA'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix.drop(columns=['SALIDA_ANO'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix['SALIDA_MES'] = pd.to_numeric(df_mix['SALIDA_MES'], errors='raise').astype('category')\n",
    "df_mix['SALIDA_DIAm'] = pd.to_numeric(df_mix['SALIDA_DIAm'], errors='raise').astype('category')\n",
    "df_mix['SALIDA_DIAs'] = pd.to_numeric(df_mix['SALIDA_DIAs'], errors='raise').astype('category')\n",
    "df_mix['SALIDA_AVANCE'] = pd.to_numeric(df_mix['SALIDA_AVANCE'], errors='raise').astype(float)\n",
    "df_mix['NOCHES'] = pd.to_numeric(df_mix['NOCHES'], errors='raise').astype('Int64')\n",
    "df_mix['DURACION_ESTANCIA'] = df_mix['DURACION_ESTANCIA'].astype('category', errors='raise')\n",
    "df_mix['REGIMEN'] = df_mix['REGIMEN'].astype('category', errors='raise')\n",
    "df_mix.drop(columns=['ID_TIPO'], inplace=True) # No usar, ID\n",
    "df_mix['TIPO'] = df_mix['TIPO'].astype('category', errors='raise')\n",
    "df_mix['USO'] = pd.to_numeric(df_mix['USO'], errors='raise').astype('Int64')\n",
    "df_mix['PAX_NUM'] = pd.to_numeric(df_mix['PAX_NUM'], errors='raise').astype('Int64')\n",
    "df_mix['PAX_CAT'] = df_mix['PAX_CAT'].astype('category', errors='raise')\n",
    "df_mix['ADULTOS'] = pd.to_numeric(df_mix['ADULTOS'], errors='raise').astype('Int64')\n",
    "df_mix['NENES'] = pd.to_numeric(df_mix['NENES'], errors='raise').astype('Int64')\n",
    "df_mix['BEBES'] = pd.to_numeric(df_mix['BEBES'], errors='raise').astype('Int64')\n",
    "df_mix.drop(columns=['ID_CLIENTE'], inplace=True) # No usar, ID\n",
    "df_mix['TIPO_CLIENTE'] = pd.to_numeric(df_mix['TIPO_CLIENTE'], errors='raise').astype('category')\n",
    "df_mix['CLIENTE'] = df_mix['CLIENTE'].astype('category', errors='raise')\n",
    "df_mix['GRUPO'] = pd.to_numeric(df_mix['GRUPO'], errors='raise').astype('category')\n",
    "df_mix.drop(columns=['ID_MONEDA'], inplace=True) # No usar, ID\n",
    "df_mix['MONEDA'] = df_mix['MONEDA'].astype('category', errors='raise')\n",
    "df_mix.drop(columns=['STATUS'], inplace=True) # No usar, redundante con variable objetivo\n",
    "df_mix.drop(columns=['MOTIVO'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['CHECKIN'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix['SUPLETORIA'] = pd.to_numeric(df_mix['SUPLETORIA'], errors='raise').astype('Int64')\n",
    "df_mix['CUNAS'] = pd.to_numeric(df_mix['CUNAS'], errors='raise').astype('Int64')\n",
    "df_mix.drop(columns=['FECHA_TOMA'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix.drop(columns=['FECHA_TOMA_ANO'], inplace=True) # No usar, contamina extrapolación\n",
    "df_mix['FECHA_TOMA_MES'] = pd.to_numeric(df_mix['FECHA_TOMA_MES'], errors='raise').astype('category')\n",
    "df_mix['FECHA_TOMA_DIAm'] = pd.to_numeric(df_mix['FECHA_TOMA_DIAm'], errors='raise').astype('category')\n",
    "df_mix['FECHA_TOMA_DIAs'] = pd.to_numeric(df_mix['FECHA_TOMA_DIAs'], errors='raise').astype('category')\n",
    "df_mix['FECHA_TOMA_AVANCE'] = pd.to_numeric(df_mix['FECHA_TOMA_AVANCE'], errors='raise').astype(float)\n",
    "df_mix.drop(columns=['FECHA_MOD'], inplace=True) # No usar, contamina extrapolación, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_MOD_ANO'], inplace=True) # No usar, contamina extrapolación, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_MOD_MES'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_MOD_DIAm'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_MOD_DIAs'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_MOD_AVANCE'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION'], inplace=True) # No usar, contamina extrapolación, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION_ANO'], inplace=True) # No usar, contamina extrapolación, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION_MES'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION_DIAm'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION_DIAs'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['FECHA_CANCELACION_AVANCE'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix['LT_TOMA_LLEGADA'] = pd.to_numeric(df_mix['LT_TOMA_LLEGADA'], errors='raise').astype('Int64')\n",
    "df_mix.drop(columns=['LT_TOMA_CANCELACION'], inplace=True) # No usar, imposible ver el futuro\n",
    "df_mix.drop(columns=['ID_FIDELIDAD'], inplace=True) # No usar, ID\n",
    "df_mix['FIDELIDAD'] = df_mix['FIDELIDAD'].astype('category', errors='raise')\n",
    "df_mix.drop(columns=['VALHAB'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix.drop(columns=['VALPEN'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix.drop(columns=['VALSERV'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix.drop(columns=['VALFIJOS'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix['COMERCIALIZADORA'] = pd.to_numeric(df_mix['COMERCIALIZADORA'], errors='raise').astype('category')\n",
    "df_mix.drop(columns=['CMVALHAB'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix.drop(columns=['CMVALPEN'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix.drop(columns=['CMCVALSERV'], inplace=True) # No usar, no está convertido y teniendo el valor total es redundante y/o dependiente de COMERCIALIZADORA\n",
    "df_mix['VALOR_USD'] = pd.to_numeric(df_mix['VALOR_USD'], errors='raise').astype(float)\n",
    "df_mix['VALOR_USD_PAX'] = pd.to_numeric(df_mix['VALOR_USD_PAX'], errors='raise').astype(float)\n",
    "df_mix['VALOR_USD_NOCHE'] = pd.to_numeric(df_mix['VALOR_USD_NOCHE'], errors='raise').astype(float)\n",
    "df_mix['VALOR_USD_PAX_NOCHE'] = pd.to_numeric(df_mix['VALOR_USD_PAX_NOCHE'], errors='raise').astype(float)\n",
    "df_mix.drop(columns=['AUTORIZO'], inplace=True) # No usar, de momento no muy claro\n",
    "df_mix['GRATIS'] = pd.to_numeric(df_mix['GRATIS'], errors='raise').astype('category')\n",
    "df_mix['PAIS'] = df_mix['PAIS'].astype('category', errors='raise')\n",
    "df_mix['CONTINENTE'] = df_mix['CONTINENTE'].astype('category', errors='raise')\n",
    "df_mix['SEGMENTO'] = df_mix['SEGMENTO'].astype('category', errors='raise')\n",
    "df_mix['FUENTE_NEGOCIO'] = df_mix['FUENTE_NEGOCIO'].astype('category', errors='raise')\n",
    "df_mix['CANCELADA'] = pd.to_numeric(df_mix['CANCELADA'], errors='raise').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3244e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix = df_mix.drop(columns=['CANCELADA'])\n",
    "\n",
    "y_mix = df_mix['CANCELADA']\n",
    "\n",
    "X_mix_train, X_mix_test, y_mix_train, y_mix_test = train_test_split(X_mix, y_mix, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b38913",
   "metadata": {},
   "source": [
    "#### Modelo Optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3220ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de la validación cruzada\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3198b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 346797, number of negative: 564634\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3106\n",
      "[LightGBM] [Info] Number of data points in the train set: 911431, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.380497 -> initscore=-0.487438\n",
      "[LightGBM] [Info] Start training from score -0.487438\n",
      "Best HyperParameters: {'learning_rate': 0.35, 'max_depth': 25, 'n_estimators': 3000, 'num_leaves': 75}\n",
      "Accuracy Test     : 0.8141210754066129\n"
     ]
    }
   ],
   "source": [
    "# Modelo LGBM Optimizado v2\n",
    "\n",
    "modelo_lgbm_cv_ohp = LGBMClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_grid_lgbm_cv_ohp = {\n",
    "    'n_estimators': [3000],\n",
    "    'max_depth': [25],\n",
    "    'learning_rate': [0.35],\n",
    "    'num_leaves': [75],\n",
    "}\n",
    "\n",
    "grid_search_lgbm_cv_ohp = GridSearchCV(\n",
    "    estimator=modelo_lgbm_cv_ohp,\n",
    "    param_grid=param_grid_lgbm_cv_ohp,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    )\n",
    "\n",
    "grid_search_lgbm_cv_ohp.fit(X_mix_train, y_mix_train)\n",
    "print(f\"Best HyperParameters: {grid_search_lgbm_cv_ohp.best_params_}\")\n",
    "\n",
    "# Asignar mejor estimador al modelo\n",
    "modelo_lgbm_cv_ohp = grid_search_lgbm_cv_ohp.best_estimator_\n",
    "\n",
    "# Resultados sobre test\n",
    "y_mix_pred_test_lgbm_cv_ohp = modelo_lgbm_cv_ohp.predict(X_mix_test)\n",
    "accuracy_test = accuracy_score(y_mix_test, y_mix_pred_test_lgbm_cv_ohp)\n",
    "print(\"Accuracy Test     :\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fbbab",
   "metadata": {},
   "source": [
    "#### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23f19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelo_lgbm_General.pkl\", \"wb\") as f:\n",
    "    pickle.dump(modelo_lgbm_cv_ohp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4dc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelo_lgbm_General.pkl\", \"rb\") as f:\n",
    "    modelo_lgbm_General = pickle.load(f)\n",
    "\n",
    "# Predecir\n",
    "#y_pred = modelo_lgbm_Grande.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1ecd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test     : 0.8141210754066129\n"
     ]
    }
   ],
   "source": [
    "y_mix_pred_test_lgbm_General = modelo_lgbm_General.predict(X_mix_test)\n",
    "accuracy_test = accuracy_score(y_mix_test, y_mix_pred_test_lgbm_General)\n",
    "print(\"Accuracy Test     :\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clavado, funciona perfectamente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
